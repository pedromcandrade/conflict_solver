{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of conflicter_solver.ipynb","provenance":[{"file_id":"1spsn4XyhbLlughqsC_L-e0hp5l6vMIIx","timestamp":1571135965913}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"X_s9L-Wo7oDm","outputId":"fd5bae5b-9e70-4a30-f799-37b9232f475b","executionInfo":{"status":"ok","timestamp":1570646604787,"user_tz":-60,"elapsed":70062,"user":{"displayName":"Pedro Andrade","photoUrl":"","userId":"00322364315034567862"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","··········\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/pedrostardust/ConflictSolver_RL/blob/master/DQN_Conflicter_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8C2vTxdnodkZ","colab":{"base_uri":"https://localhost:8080/","height":222},"outputId":"b1911c23-38c4-467f-dd74-e22ced96859a","executionInfo":{"status":"ok","timestamp":1571135580947,"user_tz":-60,"elapsed":19976,"user":{"displayName":"Pedro Andrade","photoUrl":"","userId":"00322364315034567862"}}},"source":["#@title Default title text\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","% cd \"/content/drive/My Drive/Colab Notebooks\"\n","!pwd\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/Colab Notebooks\n","/content/drive/My Drive/Colab Notebooks\n"," calendar.xlsx\t\t        ngrok\n","'Check Scheduling Input.xlsx'   ngrok-stable-linux-amd64.zip\n"," conflicter_solver.ipynb        ngrok-stable-linux-amd64.zip.1\n"," log\t\t\t        results.xlsx\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AppR9h0ybsFN","outputId":"f7a7fc88-6894-4f9d-fb7d-3d3a2dc49f0a","executionInfo":{"status":"ok","timestamp":1571135742392,"user_tz":-60,"elapsed":12408,"user":{"displayName":"Pedro Andrade","photoUrl":"","userId":"00322364315034567862"}},"colab":{"base_uri":"https://localhost:8080/","height":558}},"source":["!pip install xlsxwriter\n","!pip install tensorflow==1.14\n","!pip install simplejson"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.6/dist-packages (1.2.1)\n","Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.16.5)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.11.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.7.1)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.33.6)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.1.7)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (41.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.16.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.8.0)\n","Collecting simplejson\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/24/c35fb1c1c315fc0fffe61ea00d3f88e85469004713dab488dee4f35b0aff/simplejson-3.16.0.tar.gz (81kB)\n","\u001b[K     |████████████████████████████████| 81kB 3.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: simplejson\n","  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for simplejson: filename=simplejson-3.16.0-cp36-cp36m-linux_x86_64.whl size=114021 sha256=bb93e2b329c5115ba722ba70e83876190708cc6621b80fa679ab04442b84ca57\n","  Stored in directory: /root/.cache/pip/wheels/5d/1a/1e/0350bb3df3e74215cd91325344cc86c2c691f5306eb4d22c77\n","Successfully built simplejson\n","Installing collected packages: simplejson\n","Successfully installed simplejson-3.16.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gNGcU7VoVaTK","outputId":"de4fd812-15a3-46f6-bf6c-a1dbbacfd6b1","executionInfo":{"status":"ok","timestamp":1571135611248,"user_tz":-60,"elapsed":23006,"user":{"displayName":"Pedro Andrade","photoUrl":"","userId":"00322364315034567862"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["!rm -r -f /log/\n","\n","!mkdir log\n","\n","LOG_DIR = './log'\n","get_ipython().system_raw(\n","    'tensorboard --logdir=\"/log\" --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","\n","\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\" \n","    \n","   "],"execution_count":2,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘log’: File exists\n","--2019-10-15 10:33:10--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.206.196.238, 35.170.171.200, 54.164.252.120, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.206.196.238|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  30.9MB/s    in 0.4s    \n","\n","2019-10-15 10:33:11 (30.9 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","  inflating: ngrok                   \n","http://bd092bae.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v2xXJRf--KfH","colab":{}},"source":["import pandas as pd\n","import xlsxwriter\n","import simplejson as json\n","from datetime import *\n","\n","\n","def date_to_day(d):\n","    day = (d - date.today()).days\n","    return day\n","\n","\n","def day_to_date(day):\n","    return date.today() + timedelta(day)\n","\n","\n","def xlxs_to_matrix(filename):\n","    df = pd.read_excel(filename)\n","    matrix = df.as_matrix()\n","    matrix = np.asarray(matrix)\n","    for l in matrix:\n","        l[0] -= 1\n","        l[2] -= 1\n","\n","    return matrix\n","\n","\n","def file_to_info(filename):\n","    names = [\"D_INITIAL\", \"C_INITIAL\", \"A_INITIAL\", \"DFH\", \"DFC\", \"C_ELAPSED_TIME\",\n","             \"ADDITIONAL\", \"C_NOT_ALLOWED\", \"MORE_C_SLOTS\", \"PUBLIC_HOLIDAYS\",\n","             \"A_NOT_ALLOWED\", \"MORE_A_SLOTS\"]\n","    info = []\n","\n","    for i in range(12):\n","        df = pd.read_excel(filename, sheet_name=names[i])\n","        matrix = np.asarray(df.to_numpy())\n","        info.append(matrix)\n","\n","    return info\n","\n","\n","def render_calendar_excel(env, name):\n","    # print(env.reward_calendar())\n","    workbook = xlsxwriter.Workbook(name)\n","    ws = workbook.add_worksheet()\n","    info = workbook.add_worksheet()\n","\n","    c_format = workbook.add_format()\n","    c_format.set_pattern(1)\n","    c_format.set_bg_color('green')\n","\n","    a_format = workbook.add_format()\n","    a_format.set_pattern(1)\n","    a_format.set_bg_color('blue')\n","\n","    tolerance_used_format = workbook.add_format()\n","    tolerance_used_format.set_pattern(1)\n","    tolerance_used_format.set_bg_color('red')\n","\n","    row = 0\n","    column = 0\n","    for d in range(len(env.calendar)):\n","        day = env.calendar[d]\n","\n","        ws.write(row, column, str(day.date)) # write date\n","        # ws.write(row, column, date_to_day(day.date))\n","        row += 1\n","\n","        sorted_list = sorted(day.c_checks, key=lambda x: x.number)\n","\n","        for c in range(len(sorted_list)):  # paint c_checks\n","            ws.write(row + c, column, sorted_list[c].number, c_format)\n","\n","        row += 3\n","        for c in range(len(day.a_checks)):  # paint a_checks\n","            ws.write(row, column, day.a_checks[c].number, a_format)\n","\n","        if d % 50 != 0 or d == 0:  # don't change line\n","            column += 1\n","            row -= 4\n","        else:  # change line\n","            row += 1\n","            column = 0\n","\n","    row = 0\n","    column = 0\n","    for t in env.task_list:\n","        info.write(row, column, t.number)\n","        if t.starting_day != -1:\n","            diff = (t.due_date - t.starting_day).days\n","            if diff < 0:\n","                info.write(row, column + 1, diff, tolerance_used_format)\n","            elif t.type == \"c-check\":\n","                info.write(row, column + 1, diff, c_format)\n","            else:\n","                info.write(row, column + 1, diff, a_format)\n","        else:\n","            info.write(row, column + 1, \"Not Found\")\n","\n","        # info.write(row, column + 2, t.type)\n","\n","        if t.number % 30 != 0 or t.number == 0:  # dont change line\n","            column += 2\n","        else:\n","            row += 1\n","            column = 0\n","\n","    workbook.close()\n","\n","\n","def render_results_excel(agent, mean_rewards, max_reward, episode_conflicts, best_episode_conflicts, c_before,\n","                         c_after, a_before, a_after):\n","    workbook = xlsxwriter.Workbook('results.xlsx')\n","    worksheet = workbook.add_worksheet()\n","    # hyperparameters = workbook.add_worksheet()\n","    worksheet.write_row(0, 0, mean_rewards)\n","    hyper_strings = [\"n.layers\", \"layer1\", \"layer2\", \"layer3\", \"activation\", \"initializer\",\n","                     \"output activation\", \"optimizer\", \"gamma\", \"buffer_size\", \"batch_size\", \"target_update\",\n","                     \"learning rate\", \"max episodes\"]\n","    hyper_values = [n_layers, layer1nodes, layer2nodes, layer3nodes, activation_function,\n","                    \"tf.contrib.layers.variance_scaling_initializer()\",\n","                    \"None\", \"adam\", agent.gamma, agent.buffer_size, agent.batch_size, agent.target_update_freq,\n","                    agent.learning_rate, agent.max_episodes]\n","    worksheet.write_row(2, 0, hyper_strings)\n","    worksheet.write_row(3, 0, hyper_values)\n","\n","    max_value = [\"max value\", max_reward]\n","    worksheet.write_row(5, 0, max_value)\n","\n","    conflicts = [\"Mean conflicts:\", sum(episode_conflicts) / len(episode_conflicts),\n","                 \"Number of conflicts in best episode:\", best_episode_conflicts]\n","    worksheet.write_row(7, 0, conflicts)\n","\n","    tasks_position = [\"C tasks before:\", c_before, \"C tasks after:\", c_after, \"A tasks before:\", a_before,\n","                      \"A tasks after:\", a_after]\n","    worksheet.write_row(8, 0, tasks_position)\n","\n","    workbook.close()\n","\n","\n","def create_json(env):\n","    d = {}\n","    # go through all aircraft\n","    for i in range(env.c_initial.shape[0]):\n","        aircraft = env.c_initial[i][1]\n","        # find all tasks related with this aircraft\n","        task_list = []\n","        for task in env.task_list:\n","            if aircraft == task.tail_number:\n","                task_info = {\"id\": task.id, \"number\": task.number, \"type\": task.type, \"priority\": task.priority,\n","                             \"due date\": str(task.due_date), \"length\": task.length,\n","                             \"starting day\": str(task.starting_day), \"end day\": str(task.end_day),\n","                             \"aircraft\": task.tail_number, \"fleet\": task.fleet}\n","                task_list.append(task_info)\n","        d[aircraft] = task_list\n","\n","    j = json.dumps(d, indent=4)\n","    with open('data.json', 'w') as f:\n","        f.write(j)\n","\n","\n","def build_input_json(tasks):\n","    d = {}\n","    for task in tasks:\n","        d[task.id] = {\"due date\": str(task.due_date), \"tolerance\": str(task.tolerance), \"priority\": str(task.priority)}\n","    j = json.dumps(d, indent=4)\n","    with open('input.json', 'w') as f:\n","        f.write(j)\n","\n","\n","def task_oriented_json(env):\n","    d = {}\n","    sorted_tasks = sorted(env.task_list, key=lambda x: date_to_day(x.due_date))\n","    for task in sorted_tasks:\n","        task_info = {\"number\": task.number, \"type\": task.type, \"due date\": str(task.due_date), \"priority\": task.priority,\n","                     \"length\": task.length, \"starting day\": str(task.starting_day), \"end day\": str(task.end_day),\n","                     \"aircraft\": task.tail_number, \"fleet\": task.fleet}\n","        d[task.id] = task_info\n","\n","    j = json.dumps(d, indent=4)\n","    with open('tasks.json', 'w') as f:\n","        f.write(j)\n","\n","\n","def maintenance_plan_json(env):\n","    d = {}\n","    calendar = env.calendar\n","    for day in calendar:\n","        # c_check_ids = [task.id for task in day.c_checks]\n","        # a_check_ids = [task.id for task in day.a_checks]\n","        c_task = {}\n","        a_task = {}\n","        for task in day.c_checks:\n","            if day.date == task.end_day:\n","                c_task[task.id] = {\"state\": \"1\"}\n","            else:\n","                c_task[task.id] = {\"state\": \"0\"}\n","        for task in day.a_checks:\n","            if day.date == task.end_day:\n","                a_task[task.id] = {\"state\": \"1\"}\n","            else:\n","                a_task[task.id] = {\"state\": \"0\"}\n","        day_info = {\"c-checks\": c_task, \"a-checks\": a_task}\n","        d[str(day.date)] = day_info\n","\n","    j = json.dumps(d, indent=4)\n","    with open('plan.json', 'w') as f:\n","        f.write(j)\n","\n","\n","# finds if the tasks with the same due date were scheduled properly, i.e, if the tasks with\n","# higher priority were scheduled first\n","def evaluate_priorities():\n","    with open(\"tasks.json\") as json_file:\n","        tasks = json.load(json_file)\n","        current_due_date = 0\n","        wrong_tasks = []\n","        current_tasks = []\n","        for task_id in tasks:\n","            temp_due_date = date_to_day(datetime.strptime(tasks[task_id].get(\"due date\"), '%Y-%m-%d').date())\n","            if current_due_date == temp_due_date:\n","                current_tasks.append([task_id, tasks[task_id].get(\"priority\"), tasks[task_id].get(\"starting day\")])\n","            else:\n","                if len(current_tasks) > 1:\n","                    for i in range(len(current_tasks)):\n","                        for j in range(i, len(current_tasks)):\n","                            if current_tasks[i][1] < current_tasks[j][1] and current_tasks[i][2] < current_tasks[j][2]:\n","                                if current_tasks[i] not in wrong_tasks:\n","                                    wrong_tasks.append(current_tasks[i])\n","                                if current_tasks[j] not in wrong_tasks:\n","                                    wrong_tasks.append(current_tasks[j])\n","                current_due_date = temp_due_date\n","                current_tasks = []\n","\n","    print(wrong_tasks)\n","\n","\n","# evaluate_priorities()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YCNPPC6S7usU","colab":{}},"source":["import numpy as np\n","\n","\n","class Day:\n","    def __init__(self, date):\n","        self.date = date\n","\n","        self.c_checks = []\n","        self.a_checks = []\n","\n","\n","class Hangar:\n","    def __init__(self, n_days, n_tasks):\n","        self.n_tasks = n_tasks\n","        self.n_days = n_days\n","        self.calendar = np.zeros((n_tasks, n_days))\n","\n","    def available_day(self, task, due_date, length):\n","        for i in range(due_date, length-2, -1):\n","            if all(v == 0 for v in self.calendar[task][i-length+1:i+1]):\n","                return i\n","        return -1\n","\n","    def available_day_after(self, due_date, length):\n","        d = -1\n","        for i in range(due_date-length+1, self.n_days):\n","            possible = True\n","            for t in range(self.n_tasks):\n","                if all(v == 0 for v in self.calendar[t][i:i+length]):\n","                    d = i\n","                else:\n","                    possible = False\n","\n","            if possible:\n","                return d + length - 1\n","        return -1\n","\n","    def schedule_maintenance(self, task, day, length):\n","        self.calendar[task][day-length+1:day+1] = 1\n","\n","\n","class Task:\n","    def __init__(self, id, type, length, interval, tolerance, prev_check, number, fleet, tail_number, priority):\n","        self.id = id\n","        self.type = type\n","        self.length = length\n","        self.interval = interval\n","        self.tolerance = tolerance\n","        self.number = number\n","        self.prev_check = prev_check\n","\n","        self.fleet = fleet\n","        self.tail_number = tail_number\n","\n","        self.due_date = -1\n","        self.starting_day = -1\n","        self.end_day = -1\n","        self.hangar = -1\n","\n","        self.priority = priority\n","\n","        self.up = False\n","\n","\n","class Aircraft:\n","    def __init__(self, fleet, tail_number):\n","        self.fleet = fleet\n","        self.tail_number = tail_number\n","        self.tasks = []\n","\n","\n","class Conflict:\n","    def __init__(self, tasks):\n","        self.tasks = tasks\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GSHZlEZfGuti","colab":{}},"source":["# Earliest Due Date: EDD (changed to Earliest Scheduled Day)\n","# Tardiest Due Date: TDD (changed to Tardiest Scheduled Day)\n","# Shortest Length First: SLF\n","# Longest Length First: LLF\n","\n","\n","list_rules = [\"EDD\", \"FCFS\", \"MUF\"]\n","\n","\n","def n_rules():\n","    return len(list_rules)\n","\n","\n","def edd(tasks):\n","    bigger = 9999\n","    m = None\n","\n","    for t in tasks:\n","        if date_to_day(t.due_date) < bigger:\n","            bigger = date_to_day(t.due_date)\n","            m = t\n","    return m\n","\n","\n","def tdd(tasks):\n","    bigger = -9999\n","    m = None\n","    for t in tasks:\n","        if date_to_day(t.due_date) > bigger:\n","            bigger = date_to_day(t.due_date)\n","            m = t\n","    return m\n","\n","\n","def slf(tasks):\n","    bigger = 9999\n","    m = None\n","    for t in tasks:\n","        if t.length < bigger:\n","            bigger = t.length\n","            m = t\n","    return m\n","\n","\n","def llf(tasks):\n","    bigger = -9999\n","    m = None\n","    for t in tasks:\n","        if t.length > bigger:\n","            bigger = t.length\n","            m = t\n","    return m\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DbMu28p98apC","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"d1b0a9d6-0415-4df1-cf22-baece60d4533","executionInfo":{"status":"ok","timestamp":1571135754706,"user_tz":-60,"elapsed":6177,"user":{"displayName":"Pedro Andrade","photoUrl":"","userId":"00322364315034567862"}}},"source":["import gym\n","import copy\n","from collections import deque\n","from gym import spaces\n","import random\n","\n","MAX_PRIORITY = 1\n","\n","\n","class SchedulingEnv(gym.Env):\n","\n","    def __init__(self):\n","        self.info = file_to_info(\"Check Scheduling Input.xlsx\")\n","        self.c_initial = self.info[1]\n","        self.a_initial = self.info[2]\n","        self.additional = self.info[6]\n","        self.c_not_allowed = self.info[7]\n","        self.a_not_allowed = self.info[10]\n","        self.c_elapsed_time = self.info[5]\n","        self.n_days = 2190\n","        self.n_tasks = len(self.c_initial) + len(self.a_initial)\n","        self.a_slots = 1\n","        self.c_slots = 3\n","        self.a_length = 1\n","        self.c_length = 21\n","        self.c_interval = 3\n","\n","        self.c_tasks_before = 0\n","        self.c_tasks_after = 0\n","        self.a_tasks_before = 0\n","        self.a_tasks_after = 0\n","        self.conf_number = 0\n","        self.c_check_conf_number = 0\n","        self.a_check_conf_number = 0\n","\n","        self.last_c_days = [task[4] for task in self.c_initial]\n","        self.last_elapsed_index = np.zeros(len(self.c_initial))\n","        self.last_a_days = [task[4] for task in self.a_initial]\n","        # Calendar\n","        today_date = date.today()\n","        self.calendar = []\n","        for i in range(self.n_days):\n","            self.calendar.append(Day(today_date + timedelta(days=i)))\n","\n","        self.aircraft = []\n","        self.task_list = []\n","        self.conflicts = deque()\n","        self.last_scheduled = 0\n","        self.done = False\n","\n","        self.observation_space = spaces.Box(low=0, high=1, shape=(15, 100))     # Partial Calendar\n","        self.state = None\n","\n","        self.action_space = spaces.Discrete(4)  # Number of dispatching rules\n","\n","        self.more_tasks = False\n","\n","        self.init_aircraft()\n","        self.create_tasks()\n","        build_input_json(self.task_list)\n","\n","        self.backup = copy.deepcopy(self.task_list)\n","\n","    def reward_calendar(self):\n","        reward = 0\n","\n","        for task in self.task_list:\n","            starting_day = date_to_day(task.starting_day)\n","            due_day = date_to_day(task.due_date)\n","            if starting_day == -1:\n","                reward -= 100\n","            elif starting_day <= due_day:\n","                reward -= (due_day - starting_day) * (MAX_PRIORITY - task.priority + 1)\n","\n","                if task.type == \"c-check\":\n","                    self.c_tasks_before += 1\n","                else:\n","                    self.a_tasks_before += 1\n","\n","            else:\n","                reward -= 10 * (starting_day - due_day) * (MAX_PRIORITY - task.priority + 1)\n","\n","                if task.type == \"c-check\":\n","                    self.c_tasks_after += 1\n","                else:\n","                    self.a_tasks_after += 1\n","\n","        return reward\n","\n","    def reset(self):\n","        self.c_tasks_before = 0\n","        self.c_tasks_after = 0\n","\n","        self.a_tasks_before = 0\n","        self.a_tasks_after = 0\n","\n","        self.conf_number = 0\n","        self.c_check_conf_number = 0\n","        self.a_check_conf_number = 0\n","        self.last_scheduled = 0\n","        self.done = False\n","        self.conflicts = deque()\n","        self.more_tasks = False\n","\n","        self.c_initial = self.info[1]\n","        self.a_initial = self.info[2]\n","        self.additional = self.info[6]\n","        self.c_not_allowed = self.info[7]\n","        self.a_not_allowed = self.info[10]\n","        self.last_elapsed_index = np.zeros(len(self.c_initial))\n","        self.task_list = copy.deepcopy(self.backup)\n","\n","        self.n_tasks = len(self.c_initial) + len(self.a_initial)\n","        self.a_slots = 1\n","        self.c_slots = 3\n","        self.a_length = 1\n","        self.c_length = 21\n","        self.c_interval = 3\n","\n","        self.last_c_days = [task[4] for task in self.c_initial]\n","        self.last_a_days = [task[4] for task in self.a_initial]\n","\n","        # Calendar\n","        today_date = date.today()\n","        self.calendar = []\n","        for i in range(self.n_days):\n","            self.calendar.append(Day(today_date + timedelta(days=i)))\n","\n","        if not self.conflicts:  # if there are no conflicts #(maybe can be removed)#\n","            # schedules every task (starting in task 0) to its due date until it finds one conflict\n","            while self.last_scheduled < len(self.task_list) and not self.conflicts:\n","                if date_to_day(self.task_list[self.last_scheduled].due_date) < self.n_days:\n","                    self.schedule_maintenance(self.task_list[self.last_scheduled])\n","                self.last_scheduled += 1\n","\n","        if not self.conflicts:\n","            self.done = True\n","            self.build_state()\n","        else:\n","            self.build_state()\n","        return self.state\n","\n","    def step(self, action):\n","        self.conf_number += 1\n","        # TODO: Simulador devolve a reward imediatamente e o agente verifica\n","        # se ha um novo conflito senao nao faz nada ate haver\n","        assert(action < 4), \"Invalid action\"\n","        conflict = self.conflicts[-1]\n","\n","        if conflict.tasks[0].type == \"c-check\":\n","            self.c_check_conf_number += 1\n","        else:\n","            self.a_check_conf_number += 1\n","\n","        if action == 0:\n","            move = edd(conflict.tasks)\n","        elif action == 1:\n","            move = tdd(conflict.tasks)\n","        elif action == 2:\n","            move = llf(conflict.tasks)\n","        else:\n","            move = slf(conflict.tasks)\n","\n","        self.move_maintenance(move)\n","\n","        if not self.conflicts:  # if there are no conflicts\n","            # schedules every task (starting in task 0) to its due date until it finds one conflict\n","            while self.last_scheduled < len(self.task_list) and not self.conflicts:\n","                if date_to_day(self.task_list[self.last_scheduled].due_date) < self.n_days:\n","                    self.schedule_maintenance(self.task_list[self.last_scheduled])\n","                self.last_scheduled += 1\n","\n","        if not self.conflicts:\n","            self.done = True\n","            self.build_state()\n","        else:\n","            self.build_state()\n","\n","        reward = self.calculate_rewards(conflict.tasks)\n","\n","        return self.state, reward, self.done, {}\n","\n","    def schedule_maintenance(self, task, move=False):\n","        self.more_tasks = True\n","\n","        if move:\n","            diff = date_to_day(task.starting_day)\n","        else:\n","            diff = date_to_day(task.due_date)\n","            task.starting_day = task.due_date\n","            task.end_day = task.starting_day + timedelta(task.length-1)\n","\n","        t_type = task.type\n","\n","        if t_type == \"a-check\":\n","            self.calendar[diff].a_checks.append(task)\n","\n","        elif t_type == \"c-check\":  # Schedule c-check in the several days\n","            for i in range(date_to_day(task.starting_day), date_to_day(task.end_day) + 1):\n","                self.calendar[i].c_checks.append(task)\n","\n","        # Checking conflicts\n","        self.check_conflicts(task)\n","\n","        # Change due date following task\n","        for i in range(task.number + 1, len(self.task_list), 1):\n","            # use the id to verify the next tasks\n","            if self.task_list[i].id[:-1] == task.id[:-1]:\n","                self.task_list[i].due_date = task.starting_day + timedelta(days=task.interval)\n","                break\n","\n","    def move_maintenance(self, task):\n","        i = 0\n","        while i < len(self.conflicts):  # Erase other conflicts with this task\n","            for k in range(len(self.conflicts[i].tasks)):\n","                t = self.conflicts[i].tasks[k]\n","                if t.id == task.id:\n","                    if len(self.conflicts[i].tasks) <= 4:\n","                        del self.conflicts[i]\n","                        i -= 1\n","                        break\n","                    else:\n","                        del self.conflicts[i].tasks[k]\n","                        break\n","            i += 1\n","\n","        # Find new day\n","        found = True\n","        previous_start_day = date_to_day(task.starting_day)\n","        previous_end_day = date_to_day(task.end_day)\n","\n","        if task.type == \"a-check\":\n","            new_day = task.starting_day - timedelta(1)\n","\n","            if date_to_day(new_day) >= 0 and not task.up:\n","                task.starting_day = new_day\n","                task.end_day = task.starting_day + timedelta(task.length - 1)\n","\n","            else:\n","                # enters here only if the task could not be scheduled before its due date\n","                task.up = True\n","                new_day = task.starting_day + timedelta(1)\n","                if new_day < task.due_date + timedelta(task.tolerance) and new_day < day_to_date(self.n_days):\n","                    task.starting_day = new_day\n","                    task.end_day = task.starting_day + timedelta(task.length - 1)\n","                else:\n","                    print(\"not found:\", task.number, date_to_day(task.due_date))\n","                    found = False\n","\n","        elif task.type == \"c-check\":\n","            new_day = self.find_closest_c_day(task)\n","            if date_to_day(new_day) >= 0 and not task.up:\n","                task.starting_day = new_day\n","                task.end_day = task.starting_day + timedelta(task.length - 1)\n","            else:\n","                # enters here only if the task could not be scheduled before its due date\n","                task.up = True\n","                new_day = self.search_c_tolerance(task)\n","                if new_day < task.due_date + timedelta(task.tolerance) and new_day < day_to_date(self.n_days):\n","                    task.starting_day = new_day\n","                    task.end_day = task.starting_day + timedelta(task.length - 1)\n","                else:\n","                    print(\"not found:\", task.number, date_to_day(task.due_date))\n","                    found = False\n","\n","        if task.type == \"a-check\":  # Erase task from calendar\n","            for d in range(previous_start_day, previous_end_day + 1):\n","                i = 0\n","                while i < (len(self.calendar[d].a_checks)):\n","                    # delete the same task in the days after\n","                    t = self.calendar[d].a_checks[i]\n","                    if t.id == task.id:\n","                        del self.calendar[d].a_checks[i]\n","                        i -= 1\n","                    i += 1\n","\n","        elif task.type == \"c-check\":  # Erase task from calendar\n","            for d in range(previous_start_day, previous_end_day + 1):\n","                i = 0\n","                while i < (len(self.calendar[d].c_checks)):\n","                    # delete the same task in the days after\n","                    t = self.calendar[d].c_checks[i]\n","                    if t.id == task.id:\n","                        del self.calendar[d].c_checks[i]\n","                        i -= 1\n","                    i += 1\n","\n","        if found:\n","            self.schedule_maintenance(task, move=True)\n","        else:\n","            task.starting_day = day_to_date(-1)\n","            task.end_day = day_to_date(-1)\n","\n","    def check_conflicts(self, task):\n","        start_day = date_to_day(task.starting_day)\n","        end_day = date_to_day(task.end_day)\n","        for d in range(start_day, end_day + 1):\n","            new_conf = Conflict([task])\n","            if task.type == \"c-check\":\n","                checking_day = self.calendar[d]\n","                if len(checking_day.c_checks) > 3:\n","                    for t in checking_day.c_checks:\n","                        # if the task is not in the conflict already, add it\n","                        if self.check_containts(t, new_conf.tasks) == -1:\n","                            new_conf.tasks.append(t)\n","            if len(new_conf.tasks) > 3:\n","                self.conflicts.append(new_conf)\n","\n","            elif task.type == \"a-check\":\n","                if len(self.calendar[start_day].a_checks) > 1:\n","                    new_conf = Conflict(self.calendar[start_day].a_checks)\n","                    self.conflicts.append(new_conf)\n","\n","    # finds the closest available slot to move a c-check which is right before the last starting_day of\n","    # all the tasks in the conflict\n","    def find_closest_c_day(self, task):\n","        bigger_start_day = -99999\n","        for d in range(date_to_day(task.starting_day), date_to_day(task.end_day) + 1):\n","            conflicted = self.calendar[d].c_checks\n","            for c in conflicted:\n","                if date_to_day(c.starting_day) > bigger_start_day:\n","                    bigger_start_day = date_to_day(c.starting_day)\n","\n","        return day_to_date(bigger_start_day - task.length)\n","\n","    # finds the first available slot in the tolerance of a c-check\n","    def find_c_tolerance(self, task):\n","        due_date = date_to_day(task.due_date)\n","        for d in range(due_date, due_date + task.tolerance):\n","            if len(self.calendar[d].c_checks) < self.c_slots:\n","                return day_to_date(d)\n","        return -1\n","\n","    def search_c_tolerance(self, task):\n","        lesser = -99999\n","        for d in range(date_to_day(task.starting_day), date_to_day(task.end_day) + 1):\n","            conflicted = self.calendar[d].c_checks\n","            for c in conflicted:\n","                if date_to_day(c.starting_day) > lesser:\n","                    lesser = date_to_day(c.starting_day)\n","\n","        if lesser == -99999:\n","            lesser = date_to_day(task.starting_day)\n","\n","        if (lesser + task.length) < (date_to_day(task.due_date) + task.tolerance) and (\n","                lesser + task.length) < self.n_days:\n","            return day_to_date(lesser + task.length)\n","\n","        return day_to_date(lesser + task.length)\n","\n","    def find_c_day(self, task):\n","        lesser = 99999\n","        for d in range(date_to_day(task.starting_day), date_to_day(task.end_day) + 1):\n","            conflicted = self.calendar[d].c_checks\n","            for c in conflicted:\n","                if date_to_day(c.starting_day) < lesser:\n","                    lesser = date_to_day(c.starting_day)\n","\n","        return day_to_date(lesser - 1)\n","\n","    def simulate_move(self, task, task_list):\n","        new_day = None\n","        # Find new day\n","        if task.type == \"a-check\":\n","            new_day = task.starting_day - timedelta(1)\n","\n","            if date_to_day(new_day) >= self.a_length and not task.up:\n","                new_day = task.starting_day - timedelta(1)\n","\n","            else:\n","                new_day = task.starting_day + timedelta(1)\n","                if new_day < task.due_date + timedelta(task.tolerance) and new_day < day_to_date(self.n_days):\n","                    new_day = task.starting_day + timedelta(1)\n","                else:\n","                    new_day = date.today() - timedelta(50)\n","\n","        elif task.type == \"c-check\":\n","            new_day = self.find_c_day(task)\n","\n","            if date_to_day(new_day) >= task.length and not task.up:\n","                new_day = self.find_c_day(task)\n","\n","            else:\n","                new_day = self.search_c_tolerance(task)\n","                if new_day < task.due_date + timedelta(task.tolerance) and new_day < day_to_date(self.n_days):\n","                    new_day = self.search_c_tolerance(task)\n","                else:\n","                    new_day = date.today() - timedelta(50)\n","\n","        reward = 0\n","        for t in task_list:\n","            if t.id != task.id:\n","                day = date_to_day(t.starting_day)\n","            else:\n","                day = date_to_day(new_day)\n","\n","            due_date = date_to_day(t.due_date)\n","\n","            if day <= due_date:\n","                reward -= due_date - day\n","            else:\n","                reward -= 5 * (day - due_date)\n","\n","        return reward\n","\n","    def init_aircraft(self):\n","        self.aircraft = []\n","        for a in range(len(self.c_initial)):\n","            self.aircraft.append(Aircraft(self.c_initial[a][0], self.c_initial[a][1]))\n","\n","    def create_tasks(self):\n","        self.task_list = []\n","        task_number = 0\n","        a_checks = 0\n","        c_checks = 0\n","\n","        # C-checks\n","        # iterates over each aircraft\n","        for index in range(len(self.c_initial)):\n","            first = True\n","            task_info = self.c_initial[index]\n","            # iterates over the length values of 5 future c-checks for each aircraft\n","            for c_check_index in range(2, len(self.c_elapsed_time[0])):\n","                t_length = self.c_elapsed_time[index][c_check_index]\n","                # if length == -1 then the aircraft is phased out\n","                if t_length == -1:\n","                    break\n","                else:\n","                    # define random priority\n","                    task_priority = random.randint(1, MAX_PRIORITY)\n","                    new_task = Task(str(task_info[1]) + \"c\" + str(c_check_index-2), \"c-check\", t_length, task_info[7],\n","                                    task_info[10], task_info[4], task_number, task_info[0], task_info[1], task_priority)\n","                    if first:\n","                        new_task.prev_check = - new_task.prev_check\n","                        new_task.due_date = (date.today() + timedelta(new_task.interval + new_task.prev_check))\n","                        first = False\n","                    else:\n","                        # prev_check is the due date of the last task done on the aircraft\n","                        new_task.prev_check = date_to_day(self.aircraft[index].tasks[-1].due_date)\n","                        new_task.due_date = day_to_date(new_task.prev_check + new_task.interval)\n","\n","                    # If maintenance already passed its due date (rare) (case when t = 47)\n","                    if date_to_day(new_task.due_date) < 0:\n","                        new_task.due_date = day_to_date(t_length)\n","\n","                    # If due date is less than the number of days the task is valid\n","                    if date_to_day(new_task.due_date) < self.n_days:\n","                        self.task_list.append(new_task)         # add new task to the global task list\n","                        self.aircraft[index].tasks.append(new_task) # add new task to the respective aircraft task list\n","                        c_checks += 1\n","                        task_number += 1\n","\n","        # A-checks\n","        for index in range(len(self.a_initial)):\n","            first = True\n","            task_info = self.a_initial[index]\n","            t_length = 1\n","            current_day = 0\n","            count = 0\n","            while current_day < self.n_days:\n","                task_priority = random.randint(1, MAX_PRIORITY)\n","                new_task = Task(str(task_info[1]) + \"a\" + str(count), \"a-check\", self.a_length, task_info[7],\n","                                task_info[10], task_info[4], task_number, task_info[0], task_info[1], task_priority)\n","                if first:\n","                    new_task.prev_check = - new_task.prev_check\n","                    new_task.due_date = (date.today() + timedelta(new_task.interval + new_task.prev_check))\n","                    first = False\n","                else:\n","                    # prev_check is the due date of the last task done on the aircraft\n","                    new_task.prev_check = date_to_day(self.aircraft[index].tasks[-1].due_date)\n","                    new_task.due_date = day_to_date(new_task.prev_check + new_task.interval)\n","\n","                # If maintenance already passed its due date (rare)\n","                if date_to_day(new_task.due_date) < 0:\n","                    new_task.due_date = day_to_date(t_length)\n","\n","                # If due date is less than the number of days\n","                if date_to_day(new_task.due_date) < self.n_days:\n","                    self.task_list.append(new_task)  # add new task to the global task list\n","                    self.aircraft[index].tasks.append(new_task)  # add new task to the respective aircraft task list\n","                    a_checks += 1\n","                    task_number += 1\n","                    count += 1\n","\n","                current_day = date_to_day(new_task.due_date)\n","        print(\"A-checks: \", a_checks, \"   C-checks: \", c_checks, \"   tasks: \", len(self.task_list))\n","\n","    # creates every task\n","    def create_tasks_v2(self):\n","        self.task_list = []\n","        task_number = 0\n","        count = 0\n","        a_checks = 0\n","        c_checks = 0\n","\n","        index = 0\n","\n","        while index < self.n_days:\n","            more_tasks = False\n","\n","            for t in range(len(self.c_initial)):\n","                task = self.c_initial[t]\n","\n","                # Choose length from file\n","                length_index = int(self.last_elapsed_index[t]) + 2\n","\n","                # len(self.c_elapsed_time[0]) is always 7\n","                if length_index >= len(self.c_elapsed_time[0]):\n","                    length = 20\n","                else:\n","                    length = int(self.c_elapsed_time[t][int(self.last_elapsed_index[t]) + 2])\n","\n","                    if length != -1:\n","                        self.last_elapsed_index[t] += 1\n","                    else:\n","                        length = 10\n","\n","                length += 5\n","\n","                # Create task\n","                task_priority = random.randint(1, MAX_PRIORITY)\n","                new_task = Task(str(task[1]) + \"c\" + str(index), \"c-check\", length, task[7], task[10], task[4],\n","                                task_number, task[0], task[1], task_priority)\n","\n","                # Due date according to the last scheduling equal task\n","                if index == 0:  # If its the first task use todays date\n","                    new_task.due_date = (date.today() + timedelta(new_task.interval - self.last_c_days[t]))\n","                    new_task.starting_day = new_task.due_date\n","                    new_task.end_day = new_task.starting_day + timedelta(new_task.length - 1)\n","                else:\n","                    new_task.due_date = day_to_date(self.last_c_days[t] + new_task.interval)\n","                    new_task.starting_day = new_task.due_date\n","                    new_task.end_day = new_task.starting_day + timedelta(new_task.length - 1)\n","\n","                # If maintenance already passed its due date its gona be less than zero (rare) (case when t = 47)\n","                if date_to_day(new_task.due_date) < 0:\n","                    new_task.due_date = day_to_date(length)\n","                    new_task.starting_day = new_task.due_date\n","                    new_task.end_day = new_task.starting_day + timedelta(new_task.length - 1)\n","\n","                # If due date is less than the number of days\n","                if date_to_day(new_task.due_date) < self.n_days and length != -1:\n","                    self.task_list.append(new_task)\n","                    c_checks += 1\n","                    more_tasks = True\n","                    task_number += 1\n","                    count += 1\n","                    self.last_c_days[t] = date_to_day(new_task.due_date)\n","\n","            for t in range(len(self.a_initial)):\n","                task = self.a_initial[t]\n","                task_priority = random.randint(1, MAX_PRIORITY)\n","                new_task = Task(str(task[1]) + \"a\" + str(index), \"a-check\", self.a_length, task[7], task[10], task[4],\n","                                task_number, task[0], task[1], task_priority)\n","\n","                if index == 0:\n","                    new_task.due_date = (date.today() + timedelta(new_task.interval - self.last_a_days[t]))\n","                    new_task.starting_day = new_task.due_date\n","                    new_task.end_day = new_task.starting_day + timedelta(new_task.length - 1)\n","\n","                else:\n","                    new_task.due_date = day_to_date(self.last_a_days[t] + new_task.interval)\n","                    new_task.starting_day = new_task.due_date\n","                    new_task.end_day = new_task.starting_day + timedelta(new_task.length - 1)\n","\n","                if date_to_day(new_task.due_date) < 0:\n","                    new_task.due_date = day_to_date(self.a_length)\n","                    new_task.starting_day = new_task.due_date\n","                    new_task.end_day = new_task.starting_day + timedelta(new_task.length - 1)\n","\n","                if date_to_day(new_task.due_date) < self.n_days:\n","                    self.task_list.append(new_task)\n","                    a_checks += 1\n","                    more_tasks = True\n","                    task_number += 1\n","                    self.last_a_days[t] = date_to_day(new_task.due_date)\n","\n","                    new_task.starting_day = new_task.due_date\n","                    new_task.end_day = new_task.starting_day + timedelta(new_task.length - 1)\n","\n","            if not more_tasks:\n","                break\n","\n","            index += 1\n","\n","        print(\"a-checks: \", a_checks, \"   c-checks: \", c_checks, \"   tasks: \", len(self.task_list))\n","\n","    def build_state(self):\n","        self.state = np.zeros((15, 100))\n","        if not self.conflicts:\n","            return\n","        conf = self.conflicts[-1]\n","        conf_tasks = conf.tasks\n","\n","        # Save bigger and smaller day\n","        smaller = conf_tasks[0]\n","        bigger = conf_tasks[0]\n","        for t in conf_tasks:\n","            if t.starting_day < smaller.starting_day:\n","                smaller = t\n","            if t.starting_day > bigger.starting_day:\n","                bigger = t\n","\n","        # Select a number of days before and after the conflict\n","        left_bound = date_to_day(smaller.starting_day) - self.c_length\n","        right_bound = date_to_day(bigger.starting_day) + self.c_length\n","\n","        empty_spaces = 100 - (right_bound - left_bound)\n","\n","        left_bound -= int(empty_spaces / 2)\n","        right_bound += int(empty_spaces / 2)\n","\n","        days = []\n","        for t in conf_tasks:\n","            days.append(date_to_day(t.starting_day))\n","\n","        if left_bound < 0:\n","            right_bound += 0 - left_bound\n","            left_bound = 0\n","        if right_bound > self.n_days:\n","            left_bound -= right_bound - self.n_days\n","            right_bound = self.n_days\n","\n","        # Build State\n","        diff = 0\n","        for d in range(left_bound, right_bound):\n","            day = self.calendar[d]\n","\n","            if conf_tasks[0].type == \"c-check\":\n","                checks = sorted(day.c_checks, key=lambda x: x.number)\n","                for t in range(len(checks)):\n","                    task = checks[t]\n","                    index = self.check_containts(task, conf_tasks)\n","                    if index != -1:\n","                        self.state[index][diff] = 2\n","            elif conf_tasks[0].type == \"a-check\":\n","                checks = sorted(day.a_checks, key=lambda x: x.number)\n","                for t in range(len(checks)):\n","                    task = checks[t]\n","                    index = self.check_containts(task, conf_tasks)\n","                    if index != -1:\n","                        self.state[index][diff] = 2\n","            diff += 1\n","\n","        diff = 0\n","        array_index = len(conf_tasks)\n","        # Append tasks not in conflict\n","        for d in range(left_bound, right_bound):\n","            day = self.calendar[d]\n","            if conf_tasks[0].type == \"c-check\":\n","                for t in day.c_checks:\n","                    if self.check_containts(t, conf_tasks) == -1:\n","                        self.state[array_index][diff] += 1\n","\n","            elif conf_tasks[0].type == \"a-check\":\n","                for t in day.a_checks:\n","                    if self.check_containts(t, conf_tasks) == -1:\n","                        self.state[array_index][diff] += 1\n","            diff += 1\n","        \"\"\"\n","        array_index = len(conf_tasks)\n","        for i in range(len(not_conflicts)):\n","            t = not_conflicts[i]\n","\n","            t_index = date_to_day(t.starting_day) - left_bound\n","\n","            for k in range(t_index, t_index + t.length):\n","                if k < 100 and k > 0:\n","                    self.state[array_index][k] += 1\n","        \"\"\"\n","        #np.set_printoptions(threshold=sys.maxsize)\n","        #print(self.state)\n","\n","    def check_containts(self, task, array):\n","        for i in range(len(array)):\n","            t = array[i]\n","            if t.id == task.id:\n","                return i\n","        return -1\n","\n","    def calculate_rewards(self, tasks):\n","        reward = 0\n","\n","        for task in tasks:\n","            start_day = date_to_day(task.starting_day)\n","            due_date = date_to_day(task.due_date)\n","\n","            if start_day == -1:\n","                reward -= 100\n","            elif start_day <= due_date:\n","                reward -= (due_date - start_day) * (MAX_PRIORITY - task.priority + 1)\n","            else:\n","                reward -= 10 * (start_day - due_date) * (MAX_PRIORITY - task.priority + 1)\n","\n","        return reward\n","\n","    def render(self, mode='human'):\n","        pass\n","\n","\n","if __name__ == '__main__':\n","    \"\"\"\n","    env = SchedulingEnv()\n","    sum_rewards = 0\n","    bigger = -9999\n","    r = 0\n","\n","    conflicts = 0\n","    rewards = []\n","    c_a = []\n","    c_b = []\n","    a_a = []\n","    a_b = []\n","    conf_list = []\n","    for i in range(1):\n","        state, done = env.reset()\n","        conflicts = 0\n","        while not done:\n","            conflicts += 1\n","            action = random.randint(0, 3)\n","            next_state, reward, done, _ = env.step(action)\n","            sum_rewards += reward\n","        r = env.reward_calendar()\n","        if r > bigger:\n","            bigger = r\n","\n","        rewards.append(r)\n","        c_a.append(env.c_after)\n","        c_b.append(env.c_before)\n","        a_a.append(env.a_after)\n","        a_b.append(env.a_before)\n","        conf_list.append(conflicts)\n","\n","    env.render_excel()\n","    print(\"bigger \", r)\n","    print(\"C-after \", env.c_after, \"   C-before \", env.c_before, \"  A-after: \", env.a_after, \"   A-before: \", env.a_before)\n","    print(\"conflicts: \", conflicts)\n","\n","    print(\"mean reward \", np.mean(rewards))\n","    print(\"mean C-after \", np.mean(c_a), \"   mean C-before \", np.mean(c_b), \"  mean A-after: \",\n","          np.mean(a_a), \"   mean A-before: \", np.mean(a_b))\n","    print(\"mean conflicts: \", np.mean(conf_list))\n","\n","    env.close()\n","    \"\"\"\n","    \"\"\"\n","    e = SchedulingEnv()\n","    e.create_tasks()\n","    for t in e.task_list:\n","        print(t.id)\n","\n","    for t in e.task_list:\n","        print(\"t.number: \", t.number, \", t.id: \", t.id, \", t.dd: \", t.due_date, \", t.length: \", t.length,\n","              \", t.prev_check: \", t.prev_check, \", t.aircraft: \", t.tail_number)\n","    \"\"\"\n","    \"\"\"\n","    print(\"####################################################################\")\n","    for a in e.aircraft:\n","        print(\"aircraft: \", a.tail_number)\n","        for t in a.tasks:\n","            print(\"t.number: \", t.number, \", t.id: \", t.id)\n","        print(\"----------------------\")\n","    \"\"\"\n","    e = SchedulingEnv()\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["A-checks:  919    C-checks:  116    tasks:  1035\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"noWzzwxf8e8x","colab":{}},"source":["#\n","# DQN Helpers\n","#\n","\n","import numpy as np\n","import random\n","import tensorflow as tf\n","\n","from collections import deque\n","\n","\n","class ActionGetter:\n","    def __init__(self, n_actions, exp_init, exp_final, exp_final_frame):\n","\n","        self.n_actions = n_actions\n","        self.exp_init = exp_init\n","        self.exp_final = exp_final\n","        self.exp_final_frame = exp_final_frame\n","\n","        self.exp = self.exp_init\n","        self.slope = (exp_init - exp_final) / exp_final_frame\n","\n","        self.action = 0\n","\n","    def get_best_action(self, sess, frame_number, state, main_dqn,\n","                        evaluation=False, pre_pop=False):\n","\n","        if evaluation:\n","            output = sess.run(\n","                main_dqn.output,\n","                feed_dict={main_dqn.input: np.expand_dims(state, 0)})[0]\n","\n","            self.action = np.argmax(output)\n","        else:\n","            exp_tradeoff = np.random.rand()\n","\n","            if self.exp >= exp_tradeoff:\n","                self.action = random.randint(0, self.n_actions - 1)\n","            else:\n","                output = sess.run(\n","                    main_dqn.output,\n","                    feed_dict={main_dqn.input: [state]})\n","\n","                # output = sess.run(\n","                #    main_dqn.output,\n","                #    feed_dict={main_dqn.input: np.expand_dims(state, 0)})[0]\n","\n","                self.action = np.argmax(output)\n","\n","            if not pre_pop and frame_number <= self.exp_final_frame:\n","                self.exp = self.exp - self.slope\n","\n","        return self.action\n","\n","class FrameStacker:\n","    def __init__(self, stack_size=4, frame_width=84, frame_height=84):\n","        self.stack_size = stack_size\n","        self.frame_width = frame_width\n","        self.frame_height = frame_height\n","\n","        self.stacked_frames = deque(\n","            [np.zeros((self.frame_width, self.frame_height), dtype=np.uint8)\n","             for i in range(self.stack_size)],\n","            maxlen=self.stack_size)\n","        self.stacked_state = None\n","\n","    def stack_frames(self, state, is_reset):\n","        # frame = preprocess_frame(state)\n","        frame = state\n","\n","        if is_reset:\n","            self.stacked_frames = deque([np.zeros(\n","                (self.frame_width, self.frame_height), dtype=np.uint8) for i in\n","                range(self.stack_size)],\n","                maxlen=self.stack_size)\n","\n","            for i in range(self.stack_size):\n","                self.stacked_frames.append(frame)\n","\n","            self.stacked_state = np.stack(self.stacked_frames)  # ,axis=2\n","\n","        else:\n","            self.stacked_frames.append(frame)\n","            self.stacked_state = np.stack(self.stacked_frames)\n","\n","        return self.stacked_state\n","\n","\n","class ReplayBuffer:\n","    def __init__(self, max_size):\n","        self.buffer = [None] * (max_size + 1)\n","        self.start = 0\n","        self.end = 0\n","        self.current = self.end\n","\n","    def add(self, experience):\n","        self.buffer[self.end] = experience\n","        self.end = (self.end + 1) % len(self.buffer)\n","        self.current += 1\n","\n","        if self.end == self.start:\n","            self.start = (self.start + 1) % len(self.buffer)\n","\n","    def sample(self, batch_size):\n","        if self.current < len(self.buffer):\n","            indexes = random.sample(range(0, self.current), batch_size)\n","        else:\n","            indexes = random.sample(range(0, len(self.buffer)), batch_size)\n","\n","        return [self.buffer[i] for i in indexes]\n","\n","\n","class ModelParametersCopier:\n","    def __init__(self, estimator1, estimator2):\n","        e1_params = [t for t in tf.trainable_variables() if\n","                     t.name.startswith(estimator1.scope)]\n","        e1_params = sorted(e1_params, key=lambda v: v.name)\n","        e2_params = [t for t in tf.trainable_variables() if\n","                     t.name.startswith(estimator2.scope)]\n","        e2_params = sorted(e2_params, key=lambda v: v.name)\n","\n","        self.update_ops = []\n","        for e1_v, e2_v in zip(e1_params, e2_params):\n","            op = e2_v.assign(e1_v)\n","            self.update_ops.append(op)\n","\n","    def update_target_graph(self, sess):\n","        sess.run(self.update_ops)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AygMS8nVwjIu","colab":{}},"source":["layer1nodes = 400\n","layer2nodes = 100\n","layer3nodes = 100\n","n_layers = 2\n","activation_function = \"tf.nn.relu\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lPkIVQzces37","colab":{}},"source":["import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vb6RLrKFesLu","colab":{}},"source":["#\n","# Network\n","#\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","\n","layer1nodes = 400\n","layer2nodes = 100\n","layer3nodes = 100\n","n_layers = 2\n","activation_function = \"tf.nn.relu\"\n","\n","\n","class DQNetwork:\n","    def __init__(self, frame_height, frame_width, input_shape,\n","                 action_size, learning_rate, scope, write_summary=True):\n","\n","        self.scope = scope\n","        self.action_size = action_size\n","        self.learning_rate = learning_rate\n","        self.frame_width = frame_width\n","        self.frame_height = frame_height\n","        self.input_shape = input_shape\n","\n","        # self.input = tf.placeholder(shape=(32,) + self.input_shape,\n","        #                            dtype=tf.float32)\n","\n","        self.input = tf.placeholder(shape=[None, *input_shape],\n","                                    dtype=tf.float32)\n","\n","        self.target_Q = tf.placeholder(shape=[None], dtype=tf.float32)\n","\n","        self.actions = tf.placeholder(shape=[None], name=\"actions\",\n","                                      dtype=tf.int32)\n","        self.normalized = tf.div(\n","            tf.subtract(\n","                self.input,\n","                tf.reduce_min(self.input)\n","            ),\n","            tf.subtract(\n","                tf.reduce_max(self.input),\n","                tf.reduce_min(self.input)\n","            )\n","        )\n","\n","        self.ff1 = tf.contrib.layers.fully_connected(self.normalized,\n","                                                     num_outputs=layer1nodes,\n","                                                     activation_fn=tf.nn.relu,\n","                                                     weights_initializer=tf.contrib.layers.variance_scaling_initializer())\n","        # self.ff1_activation = tf.nn.relu(self.ff1)\n","\n","        self.ff2 = tf.contrib.layers.fully_connected(self.ff1,\n","                                                     num_outputs=layer2nodes,\n","                                                     activation_fn=tf.nn.relu,\n","                                                     weights_initializer=tf.contrib.layers.variance_scaling_initializer())\n","        # self.ff2 = tf.nn.sigmoid(self.ff2)\n","\n","        self.ff3 = tf.contrib.layers.fully_connected(self.ff2,\n","                                                     num_outputs=layer3nodes,\n","                                                     activation_fn=tf.nn.relu,\n","                                                     weights_initializer=tf.contrib.layers.variance_scaling_initializer())\n","\n","        if n_layers == 3:\n","            self.flatten = tf.layers.flatten(self.ff3)\n","        else:\n","            self.flatten = tf.layers.flatten(self.ff2)\n","\n","        self.output = tf.contrib.layers.fully_connected(self.flatten,\n","                                                        num_outputs=self.action_size,\n","                                                        activation_fn=None,\n","                                                        weights_initializer=tf.contrib.layers.variance_scaling_initializer(),\n","                                                        scope=\"asd2\"\n","                                                        )\n","\n","        self.Q = tf.reduce_sum(tf.multiply(self.output,\n","                                           tf.one_hot(self.actions,\n","                                                      self.action_size)),\n","                               axis=1)\n","\n","        self.best_action = np.argmax(self.output)\n","\n","        self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n","\n","        self.optimizer = tf.train.AdamOptimizer(self.learning_rate, epsilon=0.1)\n","        # self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-3)\n","        self.update = self.optimizer.minimize(self.loss)\n","\n","        if write_summary:\n","            tf.summary.scalar(\"loss\", self.loss)\n","            # tf.summary.histogram(\"input\", self.input)\n","            # tf.summary.histogram(\"normalized\", self.normalized)\n","            # tf.summary.histogram(\"ff1\", self.ff1)\n","            tf.summary.histogram(\"output\", self.output)\n","            tf.summary.histogram(\"q-values\", self.Q)\n","            self.summaries = tf.summary.merge_all()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GppwzgPdpD2b","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pj0YEcBLD3aB","colab":{}},"source":["from matplotlib import style\n","import matplotlib.pyplot as plt\n","\n","\n","class Agent:\n","    def __init__(self, env_name, gamma, buffer_size, batch_size, buffer_start,\n","                 target_update_freq, update_freq, learning_rate,\n","                 max_episodes, max_steps, exp_init, exp_final,\n","                 exp_final_frame, training=True,\n","                 use_target=True, restore_session=False, write_summary=True):\n","\n","        self.plot1 = None\n","        self.plot2 = None\n","\n","        self.gamma = gamma\n","        self.buffer_size = buffer_size\n","        self.batch_size = batch_size\n","        self.buffer_start = buffer_start\n","        self.target_update_freq = target_update_freq\n","        self.update_freq = update_freq\n","        self.learning_rate = learning_rate\n","        self.max_episodes = max_episodes\n","        self.max_steps = max_steps\n","        self.training = training\n","        self.use_target = use_target\n","        self.restore_session = restore_session\n","        self.exp_final_frame = exp_final_frame\n","        self.write_summary = write_summary\n","\n","        self.env = SchedulingEnv()\n","        self.best_env = copy.deepcopy(self.env)\n","        self.mean_rewards = []\n","        self.max_reward = 0\n","        # self.env = TaskDay()\n","\n","        self.action_size = self.env.action_space.n\n","        print(\"action_size: \", self.action_size)\n","        self.state_shape = self.env.observation_space.shape\n","        print(\"state_shape: \", self.state_shape)\n","\n","        self.replay_buffer = ReplayBuffer(max_size=buffer_size)\n","\n","        self.action_getter = ActionGetter(self.action_size, exp_init,\n","                                          exp_final, exp_final_frame)\n","\n","        self.dqn_network = None\n","        self.target_network = None\n","        self.network_copier = None\n","        self.summary_writer = None\n","\n","        tf.reset_default_graph()\n","\n","    def train(self):\n","        with tf.Session() as sess:\n","\n","            with tf.variable_scope('dqn_network'):\n","                self.dqn_network = DQNetwork(84, 84, self.state_shape,\n","                                             self.action_size,\n","                                             self.learning_rate, scope=\"dqn_network\")\n","\n","            if self.use_target:\n","                with tf.variable_scope('target_network'):\n","                    self.target_network = DQNetwork(84, 84, self.state_shape,\n","                                                    self.action_size,\n","                                                    self.learning_rate,\n","                                                    scope=\"target_network\")\n","\n","                self.network_copier = ModelParametersCopier(self.dqn_network,\n","                                                            self.target_network)\n","\n","            if self.write_summary:\n","                self.summary_writer = tf.summary.FileWriter('./log')\n","            sess.run(tf.global_variables_initializer())\n","            episode = 0\n","            # TODO: restore previous session\n","\n","            state = self.env.reset()\n","\n","            # In this loop the replay buffer will be pre-populated with\n","            # experiences by performing random actions\n","            for i in range(self.buffer_start):\n","                if i % 100 == 0:\n","                    print(\"Filling Buffer... \", (i * 100) / self.buffer_start, \"%\")\n","\n","                action = random.randint(0, self.action_size - 1)\n","\n","                next_state, reward, done, _ = self.env.step(action)\n","\n","                self.replay_buffer.add((state, action,\n","                                        reward, next_state, done))\n","                if done:\n","                    state = self.env.reset()\n","                else:\n","                    state = next_state\n","\n","            if self.use_target:\n","                self.network_copier.update_target_graph(sess)\n","\n","            print(\"Starting Training!\")\n","            # Training starts now\n","            all_rewards = []\n","            self.max_reward = -999999\n","\n","            best_env = self.env\n","            conflicts = 0\n","            episode_conflicts = []\n","            best_episode_conflicts = 0\n","\n","            c_before = 0\n","            c_after = 0\n","            a_before = 0\n","            a_after = 0\n","            while episode < self.max_episodes:\n","                epoch_frame = 0\n","                state = self.env.reset()\n","                sum_rewards = 0\n","                for step in range(self.max_steps):\n","                    action = self.action_getter.get_best_action(\n","                        sess,\n","                        episode,\n","                        state,\n","                        self.dqn_network,\n","                        pre_pop=False\n","                    )\n","                    next_state, reward, done, _ = self.env.step(action)\n","                    sum_rewards += reward\n","                    self.replay_buffer.add((state, action,\n","                                            reward, next_state, done))\n","\n","                    all_rewards.append(reward)\n","\n","                    if episode % self. update_freq == 0:\n","                        batch = self.replay_buffer.sample(self.batch_size)\n","\n","                        states_b = np.array([each[0] for each in batch])\n","                        actions_b = np.array([each[1] for each in batch])\n","                        rewards_b = np.array([each[2] for each in batch])\n","                        next_states_b = np.array(\n","                            [each[3] for each in batch])\n","                        terminals_b = np.array([each[4] for each in batch])\n","\n","                        if self.use_target:\n","                            q_vals_target = sess.run(\n","                                self.target_network.output,\n","                                feed_dict={\n","                                    self.target_network.input: next_states_b\n","                                }\n","                            )\n","                            target_q = rewards_b + np.invert(\n","                                terminals_b).astype(\n","                                np.float32) * self.gamma * np.amax(\n","                                q_vals_target, axis=1)\n","                        else:\n","                            q_vals_target = sess.run(\n","                                self.dqn_network.output,\n","                                feed_dict={\n","                                    self.dqn_network.input: next_states_b\n","                                }\n","                            )\n","                            target_q = rewards_b + np.invert(\n","                                terminals_b).astype(\n","                                np.float32) * self.gamma * np.amax(\n","                                q_vals_target, axis=1)  # (...q_vals_target, axis=1)\n","\n","                        \"\"\"target_qs = []\n","                        for i in range(0, self.batch_size):\n","                            terminal = terminals_b[i]\n","\n","                            if terminal:\n","                                target_qs.append(rewards_b[i])\n","                            else:\n","                                target = rewards_b[i] + self.gamma * np.max(next_states_b[i])\n","                                target_qs.append(target)\"\"\"\n","\n","                        loss, _, summaries = sess.run(\n","                            [self.dqn_network.loss, self.dqn_network.update, self.dqn_network.summaries],\n","                            feed_dict={\n","                                self.dqn_network.input: states_b,\n","                                self.dqn_network.target_Q: target_q,\n","                                self.dqn_network.actions: actions_b\n","                            })\n","                        self.summary_writer.add_summary(summaries, episode)\n","\n","                    if (self.use_target and\n","                            episode % self.target_update_freq == 0):\n","                        self.network_copier.update_target_graph(sess)\n","\n","                    episode += 1\n","                    epoch_frame += 1\n","\n","                    conflicts += 1\n","\n","                    if done:\n","                        print(\"Training... \", (episode * 100) / self.max_episodes, \"%\")\n","                        print(\"Conflicts: \", self.env.conf_number)\n","                        print(\"A-check conflicts: \", self.env.a_check_conf_number)\n","                        print(\"C-check conflicts: \", self.env.c_check_conf_number)\n","\n","                        r = self.env.reward_calendar()\n","                        self.mean_rewards.append(r)\n","                        if r > self.max_reward:\n","                            self.max_reward = r\n","                            best_episode_conflicts = conflicts\n","                            c_before = self.env.c_tasks_before\n","                            c_after = self.env.c_tasks_after\n","                            a_before = self.env.a_tasks_before\n","                            a_after = self.env.a_tasks_after\n","                            self.best_env = copy.deepcopy(self.env)\n","\n","                        print(\"Reward: \", r)\n","                        print(\"::::::::::::::::::::::::::::::::::::::::::::\")\n","\n","                        episode_conflicts.append(conflicts)\n","                        conflicts = 0\n","\n","                        break\n","\n","            print(\"Max Reward\", self.max_reward)\n","\n","            print(\"Number of conflicts in best episode: \", best_episode_conflicts)\n","            print(\"Mean number of conflicts: \", sum(episode_conflicts) / len(episode_conflicts))\n","\n","            self.plot2 = self.mean_rewards\n","\n","            render_results_excel(self, self.mean_rewards, self.max_reward, episode_conflicts, best_episode_conflicts, c_before,\n","                                 c_after, a_before, a_after)\n","\n","            render_calendar_excel(self.best_env, 'calendar.xlsx')\n","            create_json(self.best_env)\n","            task_oriented_json(self.best_env)\n","            maintenance_plan_json(self.best_env)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZD7SWQkYp5eJ","outputId":"40b3945e-ca30-4f7b-a20b-41a1a4bc57a8","executionInfo":{"status":"ok","timestamp":1571135833281,"user_tz":-60,"elapsed":36354,"user":{"displayName":"Pedro Andrade","photoUrl":"","userId":"00322364315034567862"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","if __name__ == '__main__':\n","    tf.enable_eager_execution()\n","\n","    dqn_agent = Agent(\"Seaquest-v0\",\n","                      gamma=0.9,\n","                      buffer_size=10000,\n","                      batch_size=32,\n","                      buffer_start=10000,\n","                      target_update_freq=10000,\n","                      update_freq=4,\n","                      learning_rate=0.00025,\n","                      max_episodes=500000,\n","                      max_steps=200000000,\n","                      exp_init=1.0,\n","                      exp_final=0.05,\n","                      exp_final_frame=500000)\n","    dqn_agent.train()\n","\n","    plot1 = dqn_agent.plot1\n","    plot2 = dqn_agent.plot2\n","\n","    style.use('fivethirtyeight')\n","\n","    plt.figure(figsize=(8, 6))\n","\n","    plt.xlabel('Episode', fontsize=20)\n","    plt.ylabel('Reward', fontsize=20)\n","\n","    plt.plot(plot2, color='#ee9b0b')\n","\n","    plt.show()\n","    print(\"Max\", max(plot2))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"],"name":"stderr"},{"output_type":"stream","text":["A-checks:  919    C-checks:  116    tasks:  1035\n","action_size:  4\n","state_shape:  (15, 100)\n","WARNING:tensorflow:From <ipython-input-14-55b9c47f6a7c>:41: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-14-55b9c47f6a7c>:65: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","Filling Buffer...  0.0 %\n","Filling Buffer...  1.0 %\n","Filling Buffer...  2.0 %\n","Filling Buffer...  3.0 %\n","Filling Buffer...  4.0 %\n","Filling Buffer...  5.0 %\n","Filling Buffer...  6.0 %\n","Filling Buffer...  7.0 %\n","Filling Buffer...  8.0 %\n","Filling Buffer...  9.0 %\n","Filling Buffer...  10.0 %\n","Filling Buffer...  11.0 %\n","Filling Buffer...  12.0 %\n","Filling Buffer...  13.0 %\n","Filling Buffer...  14.0 %\n","Filling Buffer...  15.0 %\n","Filling Buffer...  16.0 %\n","Filling Buffer...  17.0 %\n","Filling Buffer...  18.0 %\n","Filling Buffer...  19.0 %\n","Filling Buffer...  20.0 %\n","Filling Buffer...  21.0 %\n","Filling Buffer...  22.0 %\n","Filling Buffer...  23.0 %\n","Filling Buffer...  24.0 %\n","Filling Buffer...  25.0 %\n","Filling Buffer...  26.0 %\n","Filling Buffer...  27.0 %\n","Filling Buffer...  28.0 %\n","Filling Buffer...  29.0 %\n","Filling Buffer...  30.0 %\n","Filling Buffer...  31.0 %\n","Filling Buffer...  32.0 %\n","Filling Buffer...  33.0 %\n","Filling Buffer...  34.0 %\n","Filling Buffer...  35.0 %\n","Filling Buffer...  36.0 %\n","Filling Buffer...  37.0 %\n","Filling Buffer...  38.0 %\n","Filling Buffer...  39.0 %\n","Filling Buffer...  40.0 %\n","Filling Buffer...  41.0 %\n","Filling Buffer...  42.0 %\n","Filling Buffer...  43.0 %\n","Filling Buffer...  44.0 %\n","Filling Buffer...  45.0 %\n","Filling Buffer...  46.0 %\n","Filling Buffer...  47.0 %\n","Filling Buffer...  48.0 %\n","Filling Buffer...  49.0 %\n","Filling Buffer...  50.0 %\n","Filling Buffer...  51.0 %\n","Filling Buffer...  52.0 %\n","Filling Buffer...  53.0 %\n","Filling Buffer...  54.0 %\n","Filling Buffer...  55.0 %\n","Filling Buffer...  56.0 %\n","Filling Buffer...  57.0 %\n","Filling Buffer...  58.0 %\n","Filling Buffer...  59.0 %\n","Filling Buffer...  60.0 %\n","Filling Buffer...  61.0 %\n","Filling Buffer...  62.0 %\n","Filling Buffer...  63.0 %\n","Filling Buffer...  64.0 %\n","Filling Buffer...  65.0 %\n","Filling Buffer...  66.0 %\n","Filling Buffer...  67.0 %\n","Filling Buffer...  68.0 %\n","Filling Buffer...  69.0 %\n","Filling Buffer...  70.0 %\n","Filling Buffer...  71.0 %\n","Filling Buffer...  72.0 %\n","Filling Buffer...  73.0 %\n","Filling Buffer...  74.0 %\n","Filling Buffer...  75.0 %\n","Filling Buffer...  76.0 %\n","Filling Buffer...  77.0 %\n","Filling Buffer...  78.0 %\n","Filling Buffer...  79.0 %\n","Filling Buffer...  80.0 %\n","Filling Buffer...  81.0 %\n","Filling Buffer...  82.0 %\n","Filling Buffer...  83.0 %\n","Filling Buffer...  84.0 %\n","Filling Buffer...  85.0 %\n","Filling Buffer...  86.0 %\n","Filling Buffer...  87.0 %\n","Filling Buffer...  88.0 %\n","Filling Buffer...  89.0 %\n","Filling Buffer...  90.0 %\n","Filling Buffer...  91.0 %\n","Filling Buffer...  92.0 %\n","Filling Buffer...  93.0 %\n","Filling Buffer...  94.0 %\n","Filling Buffer...  95.0 %\n","Filling Buffer...  96.0 %\n","Filling Buffer...  97.0 %\n","Filling Buffer...  98.0 %\n","Filling Buffer...  99.0 %\n","Starting Training!\n","Training...  8.626666666666667 %\n","Conflicts:  647\n","A-check conflicts:  644\n","C-check conflicts:  3\n","Reward:  -1912\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  17.12 %\n","Conflicts:  637\n","A-check conflicts:  635\n","C-check conflicts:  2\n","Reward:  -1843\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  25.12 %\n","Conflicts:  600\n","A-check conflicts:  598\n","C-check conflicts:  2\n","Reward:  -1787\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  33.42666666666667 %\n","Conflicts:  623\n","A-check conflicts:  621\n","C-check conflicts:  2\n","Reward:  -1886\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  42.306666666666665 %\n","Conflicts:  666\n","A-check conflicts:  663\n","C-check conflicts:  3\n","Reward:  -2225\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  50.586666666666666 %\n","Conflicts:  621\n","A-check conflicts:  616\n","C-check conflicts:  5\n","Reward:  -2195\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  58.89333333333333 %\n","Conflicts:  623\n","A-check conflicts:  617\n","C-check conflicts:  6\n","Reward:  -2679\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  67.46666666666667 %\n","Conflicts:  643\n","A-check conflicts:  637\n","C-check conflicts:  6\n","Reward:  -2400\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  76.45333333333333 %\n","Conflicts:  674\n","A-check conflicts:  670\n","C-check conflicts:  4\n","Reward:  -2224\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  84.66666666666667 %\n","Conflicts:  616\n","A-check conflicts:  612\n","C-check conflicts:  4\n","Reward:  -2049\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  93.17333333333333 %\n","Conflicts:  638\n","A-check conflicts:  635\n","C-check conflicts:  3\n","Reward:  -2219\n","::::::::::::::::::::::::::::::::::::::::::::\n","Training...  101.17333333333333 %\n","Conflicts:  600\n","A-check conflicts:  597\n","C-check conflicts:  3\n","Reward:  -2158\n","::::::::::::::::::::::::::::::::::::::::::::\n","Max Reward -1787\n","Number of conflicts in best episode:  600\n","Mean number of conflicts:  632.3333333333334\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAk0AAAGUCAYAAAAoIxYiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRDpgaCIiIiLSAUMTERERkQ7+HwvSVlFc56SgAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 576x432 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Max -1787\n"],"name":"stdout"}]}]}